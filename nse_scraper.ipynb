{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nse_scraper",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datawiz1984/pyhton_note_books/blob/master/nse_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vqnP74QpUqM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**My Little Crawler**\n",
        "\n",
        "Recently I got a craving for a little pet project in machine learning. The type that make you feel like inventing the new Facebook!\n",
        "\n",
        "I decided to develop a convolution neural network in Tensorflow and keras (offcourse with python) that will predict the future price of some key equities traded on the Nigerian Stock exchange.\n",
        "\n",
        "One problem however is the unavailability of free historical prices data. Available data from the Nigerian Stock exchange website is limited to the information published in the last trading day at the floor of the exchange. Offcourse this does not meet even one of the features of a reliable training data for a machine learning problem like the one I have at hand. I now got torn between the decision to give up and quench my thrist for problem solving by spending a whole weekend bing watching The Big Bang theory, or part with my hard earn money in paying for a commercial data [which by the way I dont care to know how much].\n",
        "\n",
        "However, as a Machine learning Engineer, it wont serve me well to tow the first path  - giving up is something that I always fancy!. I therefore get my stock of coffee and an unfretting determination to solve the problem for myself and other detrmined problem conquerers.\n",
        "\n",
        "The code bellow use python pandas + Beautifulsoup + urllib + 12 hours + x cups of &#9749;  to build."
      ]
    },
    {
      "metadata": {
        "id": "iv36VJPjHhKc",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import of Relevant libraries required.\n",
        "import bs4 #Beautifulsoup\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen as uReq\n",
        "from bs4 import BeautifulSoup as msoup\n",
        "import time\n",
        "df = pd.DataFrame(columns = [ 'Symbol','Low','Open','Price','Volume','High','Change','Date'])\n",
        "df_ret = pd.DataFrame(columns = [ 'Symbol','Low','Open','Price','Volume','High','Change','Date'])\n",
        "\n",
        "def scraper_nse(counter_iter):\n",
        "  df_temp = pd.DataFrame(columns = [ 'Symbol','Low','Open','Price','Volume','High','Change','Date'])\n",
        "  my_url = \"http://www.ngtradeonline.com/Home/PriceHistory?page=\" + str(counter_iter) + \"&stockName=7UP\"\n",
        "  if counter_iter == 0:\n",
        "    my_url = \"http://www.ngtradeonline.com/Home/PriceHistory?stockName=7UP\"\n",
        "  try:\n",
        "    uClient = uReq(my_url)\n",
        "    page_html = uClient.read()\n",
        "    uClient.close()\n",
        "    page_soup = msoup(page_html,\"html.parser\")\n",
        "    table = page_soup.find_all(\"table\",class_='table')\n",
        "    df_temp = pd.read_html(str(table))\n",
        "    #print(df_temp)\n",
        "    time.sleep(2)     \n",
        "    return df_temp\n",
        "  except Exception:\n",
        "    return df_temp\n",
        "\n",
        "stocks = []\n",
        "for i in range(1,2):\n",
        "  print(\"Current Page \" + str(i))\n",
        "  df_ret= scraper_nse(i)\n",
        "  if i == 0:\n",
        "    df = df_ret\n",
        "  else:\n",
        "    df = df.append(df_ret, ignore_index = True)\n",
        "print(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}